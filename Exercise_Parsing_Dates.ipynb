{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1325,
          "sourceType": "datasetVersion",
          "datasetId": 705
        },
        {
          "sourceId": 1360,
          "sourceType": "datasetVersion",
          "datasetId": 732
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Exercise: Parsing Dates",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sunm/Learn-Data-Cleaning-in-kaggle/blob/main/Exercise_Parsing_Dates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'volcanic-eruptions:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F705%2F1325%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240828%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240828T173012Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D02d0415dd8ae03cda017dfb2af859421d62f5b73eb2cfd6252362a847fc97354555906ed2d1c6332eb26892db1cf3b8e91bc6d4a10db1c8f42df556be94ce75f8a16a509a8d3f2bb767b885e39afebb8d82e619e19e3dfbef6d6259fc8fb4ccd5ade5b84fb0a6b99cceb494d9a46fb22ba88ce3504338dada3ebc7137d5245e6c752c27e68c3014294abf2f359b759fb2f98081c67dc5606ea81c9ac4494d6e1048ee09f071799abe216fb439a65b487c4231ff3e7c837cfa63cdd5cff03dbc56c0677f177dfb37e0a9b1563f375ebe46ebca94313dd553f0640ed52b22c00d9fdb3785564ba1f16ca524a3def60becbe1591a9b44999f641b4f3058f7bb239a,earthquake-database:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F732%2F1360%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240828%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240828T173012Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D84e196c3b7ebafa08feb1841e5cf0867cf45de4462dfeb95e2a401eaf32f9b370633a883d557fbc6458bb6e54b23844242cdc9912d5109bac1fb63ba2f0103b26890d60a4b80fdeb596cce2548859330d1deac2e0e5068571ca685601732da35df21e2dea31fd3e01b69cf604e516de9cc371d0a7bff7ade5ef5e52e2172640b964b9e822ef95bb639dead3c5e9dea28d714bc65d160dd07cb38224eea7117ee009a935f19cbf4bed5d1e82686647c432499ca2371bcb4e86f3b96e532f886e2c896d095944f6bc6759b03c121697ec75f1817f9fc5d9ce7064e1b35acf8a3067736fb5b6656eb6f5036cb33c81a9ed8322a011001742507d474c087a0a54a99'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "P4r9NAryCOPc"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/parsing-dates).**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "w8j4R3biCOPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you'll apply what you learned in the **Parsing dates** tutorial.\n",
        "\n",
        "# Setup\n",
        "\n",
        "The questions below will give you feedback on your work. Run the following cell to set up the feedback system."
      ],
      "metadata": {
        "id": "1uLaZ6tXCOPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from learntools.core import binder\n",
        "binder.bind(globals())\n",
        "from learntools.data_cleaning.ex3 import *\n",
        "print(\"Setup Complete\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:00.944266Z",
          "iopub.execute_input": "2024-08-28T17:21:00.944791Z",
          "iopub.status.idle": "2024-08-28T17:21:00.952726Z",
          "shell.execute_reply.started": "2024-08-28T17:21:00.944747Z",
          "shell.execute_reply": "2024-08-28T17:21:00.951218Z"
        },
        "trusted": true,
        "id": "TkpQun4aCOPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get our environment set up\n",
        "\n",
        "The first thing we'll need to do is load in the libraries and dataset we'll be using. We'll be working with a dataset containing information on earthquakes that occured between 1965 and 2016."
      ],
      "metadata": {
        "id": "g3tlwv34COPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modules we'll use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "\n",
        "# read in our data\n",
        "earthquakes = pd.read_csv(\"../input/earthquake-database/database.csv\")\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:00.955149Z",
          "iopub.execute_input": "2024-08-28T17:21:00.955591Z",
          "iopub.status.idle": "2024-08-28T17:21:01.130514Z",
          "shell.execute_reply.started": "2024-08-28T17:21:00.95554Z",
          "shell.execute_reply": "2024-08-28T17:21:01.129273Z"
        },
        "trusted": true,
        "id": "p_l4BLG0COPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earthquakes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.132849Z",
          "iopub.execute_input": "2024-08-28T17:21:01.133379Z",
          "iopub.status.idle": "2024-08-28T17:21:01.185497Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.133316Z",
          "shell.execute_reply": "2024-08-28T17:21:01.184358Z"
        },
        "trusted": true,
        "id": "LiWURymTCOPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Check the data type of our date column\n",
        "\n",
        "You'll be working with the \"Date\" column from the `earthquakes` dataframe.  Investigate this column now: does it look like it contains dates?  What is the dtype of the column?"
      ],
      "metadata": {
        "id": "k3veFzk2COPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Your code here!\n",
        "earthquakes[\"Date\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.186935Z",
          "iopub.execute_input": "2024-08-28T17:21:01.187286Z",
          "iopub.status.idle": "2024-08-28T17:21:01.197187Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.187248Z",
          "shell.execute_reply": "2024-08-28T17:21:01.196073Z"
        },
        "trusted": true,
        "id": "1VsdopfSCOPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have answered the question above, run the code cell below to get credit for your work."
      ],
      "metadata": {
        "id": "JgGkUnqLCOPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check your answer (Run this code cell to receive credit!)\n",
        "q1.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.20002Z",
          "iopub.execute_input": "2024-08-28T17:21:01.20049Z",
          "iopub.status.idle": "2024-08-28T17:21:01.213552Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.20042Z",
          "shell.execute_reply": "2024-08-28T17:21:01.212515Z"
        },
        "trusted": true,
        "id": "3MtZOVKACOPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Line below will give you a hint\n",
        "#q1.hint()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.215304Z",
          "iopub.execute_input": "2024-08-28T17:21:01.216213Z",
          "iopub.status.idle": "2024-08-28T17:21:01.222356Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.216163Z",
          "shell.execute_reply": "2024-08-28T17:21:01.220884Z"
        },
        "trusted": true,
        "id": "6qMWO3f_COPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Convert our date columns to datetime\n",
        "\n",
        "Most of the entries in the \"Date\" column follow the same format: \"month/day/four-digit year\".  However, the entry at index 3378 follows a completely different pattern.  Run the code cell below to see this."
      ],
      "metadata": {
        "id": "o_vlHHzxCOPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "earthquakes[3378:3383]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.224519Z",
          "iopub.execute_input": "2024-08-28T17:21:01.225363Z",
          "iopub.status.idle": "2024-08-28T17:21:01.25901Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.2253Z",
          "shell.execute_reply": "2024-08-28T17:21:01.257655Z"
        },
        "trusted": true,
        "id": "0gubJOXoCOPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earthquakes.loc[2095]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.260503Z",
          "iopub.execute_input": "2024-08-28T17:21:01.260925Z",
          "iopub.status.idle": "2024-08-28T17:21:01.27337Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.260882Z",
          "shell.execute_reply": "2024-08-28T17:21:01.2721Z"
        },
        "trusted": true,
        "id": "eeEPjiKzCOPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This does appear to be an issue with data entry: ideally, all entries in the column have the same format.  We can get an idea of how widespread this issue is by checking the length of each entry in the \"Date\" column."
      ],
      "metadata": {
        "id": "-lU9Dj6DCOPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date_lengths = earthquakes.Date.str.len()\n",
        "date_lengths.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.275542Z",
          "iopub.execute_input": "2024-08-28T17:21:01.276052Z",
          "iopub.status.idle": "2024-08-28T17:21:01.306148Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.276006Z",
          "shell.execute_reply": "2024-08-28T17:21:01.304631Z"
        },
        "trusted": true,
        "id": "pHI6iXfTCOPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like there are two more rows that has a date in a different format.  Run the code cell below to obtain the indices corresponding to those rows and print the data."
      ],
      "metadata": {
        "id": "08XoH3bnCOPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.where([date_lengths == 24])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.307955Z",
          "iopub.execute_input": "2024-08-28T17:21:01.308517Z",
          "iopub.status.idle": "2024-08-28T17:21:01.318425Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.308459Z",
          "shell.execute_reply": "2024-08-28T17:21:01.317265Z"
        },
        "trusted": true,
        "id": "pfuyh7UkCOPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.where([date_lengths == 24])[1]\n",
        "print('Indices with corrupted data:', indices)\n",
        "earthquakes.loc[indices]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.322694Z",
          "iopub.execute_input": "2024-08-28T17:21:01.32311Z",
          "iopub.status.idle": "2024-08-28T17:21:01.361695Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.323068Z",
          "shell.execute_reply": "2024-08-28T17:21:01.360464Z"
        },
        "trusted": true,
        "id": "P-oGH6DBCOPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given all of this information, it's your turn to create a new column \"date_parsed\" in the `earthquakes` dataset that has correctly parsed dates in it.  \n",
        "\n",
        "**Note**: When completing this problem, you are allowed to (but are not required to) amend the entries in the \"Date\" and \"Time\" columns.  Do not remove any rows from the dataset."
      ],
      "metadata": {
        "id": "4z_gmK_hCOPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in indices:\n",
        "    earthquakes.loc[i, 'Date'] =  pd.to_datetime(earthquakes.loc[i, 'Date'], format =\"ISO8601\").date()\n",
        "\n",
        "\n",
        "earthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], format=\"%m/%d/%Y\")\n",
        "\n",
        "\n",
        "# Check your answer\n",
        "q2.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.363274Z",
          "iopub.execute_input": "2024-08-28T17:21:01.363656Z",
          "iopub.status.idle": "2024-08-28T17:21:01.452165Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.363616Z",
          "shell.execute_reply": "2024-08-28T17:21:01.451009Z"
        },
        "trusted": true,
        "id": "g2dHCIDUCOPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lines below will give you a hint or solution code\n",
        "#q2.hint()\n",
        "# q2.solution()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.453688Z",
          "iopub.execute_input": "2024-08-28T17:21:01.454055Z",
          "iopub.status.idle": "2024-08-28T17:21:01.460117Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.454016Z",
          "shell.execute_reply": "2024-08-28T17:21:01.458775Z"
        },
        "trusted": true,
        "id": "T91xry12COPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Select the day of the month\n",
        "\n",
        "Create a Pandas Series `day_of_month_earthquakes` containing the day of the month from the \"date_parsed\" column."
      ],
      "metadata": {
        "id": "2L2L_x7iCOPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try to get the day of the month from the date column\n",
        "day_of_month_earthquakes = earthquakes['date_parsed'].dt.day\n",
        "\n",
        "# Check your answer\n",
        "q3.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.461974Z",
          "iopub.execute_input": "2024-08-28T17:21:01.462481Z",
          "iopub.status.idle": "2024-08-28T17:21:01.478849Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.462401Z",
          "shell.execute_reply": "2024-08-28T17:21:01.477358Z"
        },
        "trusted": true,
        "id": "Tt1iy2fyCOPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lines below will give you a hint or solution code\n",
        "#q3.hint()\n",
        "#q3.solution()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.480881Z",
          "iopub.execute_input": "2024-08-28T17:21:01.481357Z",
          "iopub.status.idle": "2024-08-28T17:21:01.489116Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.481304Z",
          "shell.execute_reply": "2024-08-28T17:21:01.487805Z"
        },
        "trusted": true,
        "id": "1D1Fa9keCOPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Plot the day of the month to check the date parsing\n",
        "\n",
        "Plot the days of the month from your earthquake dataset."
      ],
      "metadata": {
        "id": "kO16dMF1COPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_of_month_earthquakes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.491333Z",
          "iopub.execute_input": "2024-08-28T17:21:01.492772Z",
          "iopub.status.idle": "2024-08-28T17:21:01.508199Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.492721Z",
          "shell.execute_reply": "2024-08-28T17:21:01.506807Z"
        },
        "trusted": true,
        "id": "O1HZ9JexCOPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(day_of_month_earthquakes, kde = True )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:01.510226Z",
          "iopub.execute_input": "2024-08-28T17:21:01.51069Z",
          "iopub.status.idle": "2024-08-28T17:21:02.034339Z",
          "shell.execute_reply.started": "2024-08-28T17:21:01.510645Z",
          "shell.execute_reply": "2024-08-28T17:21:02.033081Z"
        },
        "trusted": true,
        "id": "lxiVivNMCOPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does the graph make sense to you?"
      ],
      "metadata": {
        "id": "19kJsYnyCOPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check your answer (Run this code cell to receive credit!)\n",
        "q4.check()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:02.035692Z",
          "iopub.execute_input": "2024-08-28T17:21:02.036023Z",
          "iopub.status.idle": "2024-08-28T17:21:02.045495Z",
          "shell.execute_reply.started": "2024-08-28T17:21:02.035986Z",
          "shell.execute_reply": "2024-08-28T17:21:02.044272Z"
        },
        "trusted": true,
        "id": "lgMrxeSHCOPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Line below will give you a hint\n",
        "#q4.hint()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:02.047264Z",
          "iopub.execute_input": "2024-08-28T17:21:02.047934Z",
          "iopub.status.idle": "2024-08-28T17:21:02.052963Z",
          "shell.execute_reply.started": "2024-08-28T17:21:02.047879Z",
          "shell.execute_reply": "2024-08-28T17:21:02.051864Z"
        },
        "trusted": true,
        "id": "-CEpCaHeCOPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Optional) Bonus Challenge\n",
        "\n",
        "For an extra challenge, you'll work with a [Smithsonian dataset](https://www.kaggle.com/smithsonian/volcanic-eruptions) that documents Earth's volcanoes and their eruptive history over the past 10,000 years\n",
        "\n",
        "Run the next code cell to load the data."
      ],
      "metadata": {
        "id": "wNSjeHafCOPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "volcanos = pd.read_csv(\"../input/volcanic-eruptions/database.csv\")\n",
        "volcanos"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:02.05434Z",
          "iopub.execute_input": "2024-08-28T17:21:02.055214Z",
          "iopub.status.idle": "2024-08-28T17:21:02.094428Z",
          "shell.execute_reply.started": "2024-08-28T17:21:02.055163Z",
          "shell.execute_reply": "2024-08-28T17:21:02.093198Z"
        },
        "trusted": true,
        "id": "KVsOy1XUCOPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try parsing the column \"Last Known Eruption\" from the `volcanos` dataframe. This column contains a mixture of text (\"Unknown\") and years both before the common era (BCE, also known as BC) and in the common era (CE, also known as AD)."
      ],
      "metadata": {
        "id": "KM4bIix9COPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "volcanos['Last Known Eruption'].sample(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:02.096074Z",
          "iopub.execute_input": "2024-08-28T17:21:02.0966Z",
          "iopub.status.idle": "2024-08-28T17:21:02.106433Z",
          "shell.execute_reply.started": "2024-08-28T17:21:02.096544Z",
          "shell.execute_reply": "2024-08-28T17:21:02.105129Z"
        },
        "trusted": true,
        "id": "5XylZdm1COPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unk_counts = volcanos['Last Known Eruption'].isin(['Unknown']).sum()\n",
        "unk_counts"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:02.107877Z",
          "iopub.execute_input": "2024-08-28T17:21:02.108221Z",
          "iopub.status.idle": "2024-08-28T17:21:02.119845Z",
          "shell.execute_reply.started": "2024-08-28T17:21:02.108183Z",
          "shell.execute_reply": "2024-08-28T17:21:02.118679Z"
        },
        "trusted": true,
        "id": "87EtVc2uCOPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_year(year):\n",
        "    year_split = year.split()\n",
        "    if year_split[-1] == 'BCE':\n",
        "        year = int(year_split[0])\n",
        "        return -year\n",
        "    elif year_split[-1] == 'CE':\n",
        "        year = int(year_split[0])\n",
        "        return year\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "volcanos['Last Known Eruption'] = volcanos['Last Known Eruption'].apply(convert_year)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:02.121504Z",
          "iopub.execute_input": "2024-08-28T17:21:02.121862Z",
          "iopub.status.idle": "2024-08-28T17:21:02.134685Z",
          "shell.execute_reply.started": "2024-08-28T17:21:02.121825Z",
          "shell.execute_reply": "2024-08-28T17:21:02.133468Z"
        },
        "trusted": true,
        "id": "-bPdzt8NCOPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "volcanos.dropna(subset=['Last Known Eruption'], inplace=True)\n",
        "volcanos.sort_values(by='Last Known Eruption', ascending=True, inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:38.954906Z",
          "iopub.execute_input": "2024-08-28T17:21:38.955421Z",
          "iopub.status.idle": "2024-08-28T17:21:38.967193Z",
          "shell.execute_reply.started": "2024-08-28T17:21:38.955376Z",
          "shell.execute_reply": "2024-08-28T17:21:38.965875Z"
        },
        "trusted": true,
        "id": "Qu3HKeCpCOPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(volcanos['Last Known Eruption'], kde=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T17:21:41.358522Z",
          "iopub.execute_input": "2024-08-28T17:21:41.358957Z",
          "iopub.status.idle": "2024-08-28T17:21:41.800411Z",
          "shell.execute_reply.started": "2024-08-28T17:21:41.358919Z",
          "shell.execute_reply": "2024-08-28T17:21:41.799257Z"
        },
        "trusted": true,
        "id": "zrslJ2_ZCOPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyjRshfvCOPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Optional) More practice\n",
        "\n",
        "If you're interested in graphing time series, [check out this tutorial](https://www.kaggle.com/residentmario/time-series-plotting-optional).\n",
        "\n",
        "You can also look into passing columns that you know have dates in them  the `parse_dates` argument in `read_csv`. (The documention [is here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).) Do note that this method can be very slow, but depending on your needs it may sometimes be handy to use.\n",
        "\n",
        "# Keep going\n",
        "\n",
        "In the next lesson, learn how to [**work with character encodings**](https://www.kaggle.com/alexisbcook/character-encodings)."
      ],
      "metadata": {
        "id": "ivPQyMGlCOPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*"
      ],
      "metadata": {
        "id": "0dvsHo67COPo"
      }
    }
  ]
}